{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage fédéré de réseaux de neurones\n",
    "# Lionel Delphin-Poulat, Bassem Jaber, Nour El Houda Zribi\n",
    "Ce projet a pour objectif de comparer les performances d'un apprentissage classique à un apprentissage fédéré dans le cas d'un réseau de neurones entraîné avec les données du Challenge DCASE 2018 disponibles ici :\"http://dcase.community/challenge2018/task-general-purpose-audio-tagging\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons par importer l'ensemble des bibliothèques et fonctions auxiliaires qui nous servirons dans ce projet.\\\n",
    "Attention à l'utilisation de tensorflow, lorsque vous installez tensorflow-gpu, il faut faire le nécessaire pour que les calculs se fassent correctement sur votre carte graphique, lire la documentation dans les sites suivant pour effectuer la démarche correspondante (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html https://www.tensorflow.org/install/gpu https://developer.nvidia.com/cudnn )\\\n",
    "Dans le cas où votre carte graphique n'est pas compatible où que l'installation ne se déroule pas comme souhaité, installez simplement tensorflow et les calculs s'effectueront sur le processeur, mais ce dernier possède en général une puissance de calcul beaucoup plus faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow-gpu\n",
    "#!pip install soundfile\n",
    "#!pip install librosa\n",
    "#!pip install tensorboard\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import sklearn.utils\n",
    "import keras.backend as K\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, MaxPooling2D, Input, Dropout, Dense, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons la fonction suivante pour ré-échantilloner le fichier si nécessaire et surtout obtenir les amplitudes du fichier son analysé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sound_data(filename, sr=None):\n",
    "    \"\"\"\n",
    "    read sound file, convert it to a target frequency and convert it to mono\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        sound filename\n",
    "    sr: int\n",
    "        sampling rate in Hz\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: ndarray\n",
    "        an ndarray of amplitude values\n",
    "    sr: int\n",
    "        the sampling frequency of the returned signal\n",
    "    \"\"\"\n",
    "    \n",
    "    # read the sound file\n",
    "    data, fsr = soundfile.read(filename)\n",
    "    \n",
    "    # resample if required\n",
    "    if sr is not None and sr != fsr:\n",
    "        data_resample = librosa.resample(data.T, fsr, sr)\n",
    "    else:\n",
    "        data_resample = data.T\n",
    "        sr = fsr\n",
    "    \n",
    "    # if there is more than one audio channel\n",
    "    # convert to mono by averaging over all the channels\n",
    "    if len(data_resample.shape) > 1:\n",
    "        data_resample = np.average(data_resample, axis=0)\n",
    "        \n",
    "    return data_resample, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons maintenant les fonctions qui nous permettront de définir notre réseau de neurones.\\\n",
    "Nous commençons par définir un bloc de notre réseau puis le modèle global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggish_convolution_block(input,\n",
    "                             kernel_size=(3, 3),\n",
    "                             filters=128,\n",
    "                             pool_size=(2, 2),\n",
    "                             pool_strides=(2, 2),\n",
    "                             padding='same',\n",
    "                             data_format='channels_first',\n",
    "                             drop_out=None,\n",
    "                             use_bias=False):\n",
    "    \"\"\"\n",
    "    Define a vggish convolution block\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input :\n",
    "        input Tensor\n",
    "    kernel_size : `int` or `tuple`\n",
    "        kernel filter sizes\n",
    "    filters :\n",
    "        number of output units\n",
    "    pool_size :\n",
    "        sizes for max-pooling at model output\n",
    "    pool_strides :\n",
    "        strides for max-pooling at mode output\n",
    "    padding : str\n",
    "        padding format for convolution layers\n",
    "    data_format : str\n",
    "        data format to indicate the channel position\n",
    "    drop_out : bool\n",
    "        add dropout layer after activation funcion\n",
    "    use_bias : bool\n",
    "        add bias parameters\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor\n",
    "        output tensor\n",
    "    \"\"\"\n",
    "\n",
    "    naxis = 1 if data_format == 'channels_first' else -1\n",
    "\n",
    "    cnn = Conv2D(filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 padding=padding,\n",
    "                 data_format=data_format,\n",
    "                 use_bias=use_bias,\n",
    "                 kernel_initializer='he_uniform')(input)\n",
    "\n",
    "    cnn = BatchNormalization(axis=naxis)(cnn)\n",
    "\n",
    "    cnn = Activation('relu')(cnn)\n",
    "\n",
    "    if drop_out is not None:\n",
    "        cnn = Dropout(rate=drop_out)(cnn)\n",
    "\n",
    "    cnn = Conv2D(filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 padding=padding,\n",
    "                 data_format=data_format,\n",
    "                 use_bias=use_bias,\n",
    "                 kernel_initializer='he_uniform')(cnn)\n",
    "\n",
    "    cnn = BatchNormalization(axis=naxis)(cnn)\n",
    "\n",
    "    cnn = Activation('relu')(cnn)\n",
    "\n",
    "    cnn = MaxPooling2D(pool_size=pool_size,\n",
    "                       strides=pool_strides,\n",
    "                       data_format=data_format)(cnn)\n",
    "\n",
    "    if drop_out is not None:\n",
    "        cnn = Dropout(rate=drop_out)(cnn)\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggish_model(input_shape,\n",
    "                 classes,\n",
    "                 other_class=True,\n",
    "                 filters=[64, 128, 256, 512],\n",
    "                 n_layers=None,\n",
    "                 kernel_size=(3, 3),\n",
    "                 pool_size=(2, 2),\n",
    "                 data_format='channels_first',\n",
    "                 drop_out=None,\n",
    "                 output_activation='softmax'):\n",
    "    if isinstance(input_shape, list):\n",
    "        input_layer = Input(input_shape[0], name='spectrogram')\n",
    "        auxiliary_input = Input(input_shape[1], name=\"auxiliary\")\n",
    "    else:\n",
    "        input_layer = Input(input_shape, name='spectrogram')\n",
    "        auxiliary_input = None\n",
    "\n",
    "    current_layer = input_layer\n",
    "\n",
    "    use_bias = False\n",
    "    padding = 'same'\n",
    "\n",
    "    class_count = classes if other_class else classes - 1\n",
    "    dense_dropout = 0.2\n",
    "\n",
    "    if not isinstance(filters, list):\n",
    "        if n_layers is None:\n",
    "            raise ValueError(\"n_layers can not be none if filters is not a list\")\n",
    "        filter_list = n_layers * [filters]\n",
    "    else:\n",
    "        filter_list = filters\n",
    "        n_layers = len(filters)\n",
    "\n",
    "    for layer in range(n_layers):\n",
    "        current_layer = vggish_convolution_block(current_layer,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 filters=filter_list[layer],\n",
    "                                                 pool_size=pool_size,\n",
    "                                                 padding=padding,\n",
    "                                                 data_format=data_format,\n",
    "                                                 use_bias=use_bias,\n",
    "                                                 drop_out=drop_out)\n",
    "\n",
    "    #    current_layer = GlobalMaxPooling2D(data_format=data_format)(current_layer)\n",
    "\n",
    "    layer_shape = K.int_shape(current_layer)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        pool_size = layer_shape[2:]\n",
    "    else:\n",
    "        pool_size = layer_shape[1:-1]\n",
    "\n",
    "    current_layer = MaxPooling2D(pool_size=pool_size,\n",
    "                                 strides=pool_size,\n",
    "                                 data_format=data_format)(current_layer)\n",
    "\n",
    "    current_layer = Flatten(data_format=data_format)(current_layer)\n",
    "\n",
    "    current_layer = Dropout(rate=dense_dropout)(current_layer)\n",
    "\n",
    "    if auxiliary_input is not None:\n",
    "        current_layer = concatenate([current_layer, auxiliary_input])\n",
    "\n",
    "    # current_layer = Dropout(rate=dense_dropout)(current_layer)\n",
    "    current_layer = Dense(units=class_count,\n",
    "                          kernel_initializer='he_uniform',\n",
    "                          activation=output_activation)(current_layer)\n",
    "\n",
    "    if auxiliary_input is not None:\n",
    "        model = Model([input_layer, auxiliary_input], current_layer)\n",
    "    else:\n",
    "        model = Model(input_layer, current_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons ici le Data Generator.\\\n",
    "Son rôle est de gagner du temps de calcul lors de l'apprentissage.\\\n",
    "Au lieu de balayer toute notre base de données à chacun de nos calculs pour chaque batch de données, il ne va prendre en compte que les données pertinentes au calcul en question et ne pas charger le reste de la base de données, cela permet d'économiser du temps de calcul et de la RAM, ce qui nous est très utile pour accélérer l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Class: Data generator\n",
    "# =====================================================================\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 train_filename_list,\n",
    "                 labels,\n",
    "                 samples_directory,\n",
    "                 batch_size=256,\n",
    "                 undersampling='uniform',\n",
    "                 shuffle=True,\n",
    "                 frame_window_length=None,\n",
    "                 frame_window_hop=None,\n",
    "                 data_format='channels_first',\n",
    "                 debug=False):\n",
    "        \"\"\"Data generator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_filename_list : list of str\n",
    "           list of file base names\n",
    "\n",
    "        labels : ndarray\n",
    "           labels\n",
    "\n",
    "        samples_directory : str\n",
    "            directory where to find the data\n",
    "\n",
    "        batch_size : int\n",
    "           Batch size\n",
    "\n",
    "        undersampling : str ('uniform','none')\n",
    "           Uniform undersampling or none\n",
    "\n",
    "        shuffle : bool\n",
    "           shuffle ont epoch end\n",
    "\n",
    "        separate_channels : bool\n",
    "            process each channel separately\n",
    "\n",
    "        frame_window_length : int\n",
    "            number of frames for a patch. If nothing is provided, the whole file is considered as input\n",
    "\n",
    "        frame_window_hop : int\n",
    "            number of frames between two windows. This parameter is ignored if frame_window_length is None\n",
    "\n",
    "        data_format : {'channels_first', 'channels_last'}\n",
    "            ordering of input dimensions\n",
    "\n",
    "        debug : bool\n",
    "            specifies if debug info must be output while generating the data\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # inits\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.undersampling = undersampling\n",
    "        self.train_filename_list = train_filename_list\n",
    "        self.samples_directory = samples_directory\n",
    "        self.shuffle = shuffle\n",
    "        # get the different classes\n",
    "        classes = np.unique(self.labels)\n",
    "        # and their count\n",
    "        self.nr_class = len(classes)\n",
    "        # compute the least represented class\n",
    "        class_weight = sklearn.utils.compute_class_weight('balanced', classes, self.labels)\n",
    "        min_ex = np.argmax(class_weight)\n",
    "        # compute the number of sample in this class\n",
    "        self.values_to_sample = np.sum(self.labels == min_ex)\n",
    "\n",
    "        self.frame_window_length = frame_window_length\n",
    "        self.frame_window_hop = frame_window_hop\n",
    "\n",
    "        if self.frame_window_length is not None and self.frame_window_hop is None:\n",
    "            self.frame_window_hop = self.frame_window_length\n",
    "\n",
    "        if self.frame_window_length is not None:\n",
    "            # retrieve the file lengths for all the file in the database\n",
    "            # it assumes that each numpy file has shape (n_frames, n_frequencies)\n",
    "            self._file_lengths = []\n",
    "            for file_id in train_filename_list:\n",
    "                feature_filename = os.path.join(self.samples_directory, file_id + 'normalized.npy')\n",
    "                features = np.load(feature_filename)\n",
    "                self._file_lengths.append(features.shape[0])\n",
    "        else:\n",
    "            self._file_lengths = None\n",
    "\n",
    "        self.data_format = data_format\n",
    "        self.debug = debug\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __compute_batches(self):\n",
    "        \"\"\"\n",
    "        get the number of batches\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        batches : int\n",
    "            the number of batches\n",
    "\n",
    "        \"\"\"\n",
    "        self.batches = len(self.indexes) // self.batch_size\n",
    "        if not self.shuffle:  # not in training mode\n",
    "            if len(self.indexes) % self.batch_size != 0:\n",
    "                self.batches += 1\n",
    "        if self.debug:\n",
    "            print('number of training batches %s' % self.batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        # batch size\n",
    "        if self.batches < 1:\n",
    "            self.__compute_batches()\n",
    "        return self.batches\n",
    "\n",
    "    def __get_data_from_indexes(self, indexes, start, stop):\n",
    "        \"\"\"\n",
    "        get a batch of data from start\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        indexes : ndarray\n",
    "            sample indices of the whole data\n",
    "\n",
    "        start : int\n",
    "            index of the first sample to be included in the batch\n",
    "        stop :\n",
    "            index of the last sample (not included in the batch)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data : ndarray\n",
    "            batch of input data\n",
    "\n",
    "        label : ndarray\n",
    "            batch of the corresponding one-hot-encoded labels\n",
    "        \"\"\"\n",
    "\n",
    "        begs = None\n",
    "\n",
    "        if self.frame_window_length is not None:\n",
    "            # retrieve the file names and corresponding labels\n",
    "            training_files_tmp = [self.train_filename_list[k] for k in indexes[start:stop, 0]]\n",
    "            y_tmp = [self.labels[k] for k in indexes[start:stop, 0]]\n",
    "            # retrieve the corresponding window start frames\n",
    "            begs = [k for k in indexes[start:stop, 1]]\n",
    "\n",
    "        else:\n",
    "            # retrieve the file names and corresponding labels\n",
    "            training_files_tmp = [self.train_filename_list[k] for k in indexes[start:stop]]\n",
    "            y_tmp = [self.labels[k] for k in indexes[start:stop]]\n",
    "\n",
    "        # get actual data from indices\n",
    "        X, y = self.__data_generation(training_files_tmp, y_tmp, begs)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select batch\n",
    "        start = index * self.batch_size\n",
    "        stop = min((index + 1) * self.batch_size,\n",
    "                   self.nr_examples)  # if needed provide smaller batch (used in validation)\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__get_data_from_indexes(self.indexes, start, stop)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __get_patches(self, file_indices):\n",
    "        \"\"\"\n",
    "        compute all the samples that can be obtained from the file given in file_indices.\n",
    "        each sample is identified by a file id and a start frame within the corresponding file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_indices: list of int\n",
    "            numerical indices of feature files\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        patches: ndarray (number of samples, 2)\n",
    "            array of samples indices (index : couple of file id and start frame)\n",
    "        \"\"\"\n",
    "        patches = []\n",
    "        for file_id in file_indices:\n",
    "            # get the array of start frames\n",
    "            begins = get_begins(self._file_lengths[file_id], self.frame_window_length, self.frame_window_hop)\n",
    "            # for file_id build a two dimensionnal array\n",
    "            # [[file_id, begs[0]], [file_id, begs[1]],...,  [file_id, begs[n_window-1]]]\n",
    "            file_ids = np.repeat([file_id], len(begins))\n",
    "            cur_patch = np.stack((file_ids, begins), axis=-1)\n",
    "            patches.append(cur_patch)\n",
    "        return np.concatenate(patches)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "\n",
    "        function that prepares the indices ot the samples that will be used during one training epoch\n",
    "\n",
    "        \"\"\"\n",
    "        if self.debug:\n",
    "            print(\"generating shuffle % s\" % self.undersampling)\n",
    "        # undersampling\n",
    "        if self.undersampling == 'uniform':\n",
    "            all_indexes = np.arange(len(self.labels))\n",
    "            self.indexes = [None] * (self.values_to_sample * self.nr_class)\n",
    "\n",
    "            # print(\"%d %d\" % (self.values_to_sample,  self.nr_class))\n",
    "\n",
    "            for i in range(self.nr_class):\n",
    "                # for each class pick-up self.values_to_sample samples\n",
    "                self.indexes[i * self.values_to_sample: (i + 1) * self.values_to_sample] = \\\n",
    "                    np.random.choice(all_indexes[self.labels == i], self.values_to_sample, replace=False)\n",
    "\n",
    "            if self.debug:\n",
    "                print('# of files after undersampling %s' % len(self.indexes))\n",
    "        else:\n",
    "            self.indexes = np.arange(len(self.train_filename_list))\n",
    "            if self.debug:\n",
    "                print('# of files %s' % len(self.indexes))\n",
    "\n",
    "        # self.indexes contain the file indices that will be used on this epoch\n",
    "\n",
    "        # if we need to get smaller patches for each file\n",
    "        if self.frame_window_length is not None:\n",
    "            # elements of the array are in the following form\n",
    "            # [file_id, beginning frame]\n",
    "            self.indexes = self.__get_patches(self.indexes)\n",
    "\n",
    "        if self.debug:\n",
    "            print(self.indexes[:20])\n",
    "\n",
    "        self.nr_examples = len(self.indexes)\n",
    "\n",
    "        # shuffle data if required (must be True for training)\n",
    "        # must be False for test or validation use\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            if self.debug:\n",
    "                print(\"after shuffle\")\n",
    "                print(self.indexes[:20])\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"shuffle size %d\" % len(self.indexes))\n",
    "            print(\"indexes shapes {}\".format(self.indexes.shape))\n",
    "            print(\"indexes dims {}\".format(self.indexes.ndim))\n",
    "\n",
    "        # uptate the number of batches\n",
    "        self.__compute_batches()\n",
    "\n",
    "    def __data_generation(self, training_files_tmp, y_tmp, begs=None):\n",
    "        # Initialization\n",
    "        x = []\n",
    "\n",
    "        # prepare one-hot encoding arrays\n",
    "\n",
    "        y = np.zeros((len(y_tmp), self.nr_class))\n",
    "\n",
    "        previous_feature_fn = ''\n",
    "        all_features_data = None\n",
    "        # Generate data\n",
    "        for j, ID in enumerate(training_files_tmp):\n",
    "            # load data\n",
    "            feature_filename = os.path.join(self.samples_directory, training_files_tmp[j] + 'normalized.npy')\n",
    "\n",
    "            if self.debug:\n",
    "\n",
    "                if begs is not None:\n",
    "                    start_stop = '[%d:%d]' % (begs[j], begs[j] + self.frame_window_length)\n",
    "                else:\n",
    "                    start_stop = '[:]'\n",
    "\n",
    "                print(\"loading %s %s label %d %s\" % (\n",
    "                    training_files_tmp[j], feature_filename,\n",
    "                    y_tmp[j],\n",
    "                    start_stop))\n",
    "\n",
    "            if previous_feature_fn != feature_filename or all_features_data is None:\n",
    "                # only load the data when a new file is found\n",
    "                all_features_data = np.load(feature_filename)\n",
    "                previous_feature_fn = feature_filename\n",
    "\n",
    "            features_data = all_features_data\n",
    "\n",
    "            if begs is not None:\n",
    "                # we must extract the corresponding signal patch\n",
    "                beg = begs[j]\n",
    "                end = begs[j] + self.frame_window_length\n",
    "\n",
    "                features_data = features_data[beg:end, :]\n",
    "\n",
    "                if features_data.shape[0] < self.frame_window_length:\n",
    "                    # the signal is not long enough\n",
    "                    pad_size = self.frame_window_length - features_data.shape[0]\n",
    "                    # pad it with 0s\n",
    "                    features_data = np.pad(features_data, ((0, pad_size), (0, 0)), mode='wrap')\n",
    "\n",
    "            if self.debug:\n",
    "                print(\"features shape {}\".format(features_data.shape))\n",
    "\n",
    "            features_data = np.reshape(features_data,(1,)+features_data.shape)\n",
    "            x.append(features_data)\n",
    "\n",
    "            # one hot encoding\n",
    "            y[j][y_tmp[j]] = 1\n",
    "\n",
    "        x_data = np.array(x)\n",
    "\n",
    "        if self.data_format == 'channels_last':\n",
    "            # move channel axis to the last position\n",
    "            x_data = np.moveaxis(x_data, [1, 2, 3], [3, 1, 2])\n",
    "\n",
    "        return x_data, y\n",
    "\n",
    "    @property\n",
    "    def file_lengths(self):\n",
    "        return self._file_lengths\n",
    "\n",
    "\n",
    "def get_begins(file_length, frame_window_length, frame_window_hop):\n",
    "    \"\"\"\n",
    "\n",
    "    get the frame indices where each window starts;\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_length : int\n",
    "        total file length in frames\n",
    "\n",
    "    frame_window_length : int\n",
    "        window size in frames\n",
    "\n",
    "    frame_window_hop : int\n",
    "        window hop in frames\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    begins : 'numpy.array'\n",
    "        an array containing the window starts indices\n",
    "\n",
    "    \"\"\"\n",
    "    if file_length < frame_window_length:\n",
    "        begins = [0]\n",
    "    else:\n",
    "        begins = np.arange(0, file_length - frame_window_length + 1, frame_window_hop)\n",
    "    return begins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nettoyons notre session keras pour pallier à un problème de fuite de mémoire sur keras apparu avec Windows 10. Cela nous permet de faire différents apprentissages superposés sans encombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons ici l'ensemble des paramètres utilisés par la suite. Nous chargeons les donnés, définissons les classes, les listes de fichier audio pour l'entraînement, la validation, les tests, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "data_label=pd.read_csv('C:/Users/jaber/Downloads/PFE/FSDKaggle2018.meta/test_post_competition_scoring_clips.csv')\n",
    "basename = 'C:/Users/jaber/Downloads/PFE/'\n",
    "data_train=pd.read_csv('C:/Users/jaber/Downloads/PFE/fold1_train.txt', sep='\\t')\n",
    "train_values=data_train.values\n",
    "data_valid=pd.read_csv('C:/Users/jaber/Downloads/PFE/fold1_valid.txt', sep='\\t')\n",
    "valid_values=data_valid.values\n",
    "data_test=pd.read_csv('C:/Users/jaber/Downloads/PFE/fold1_test.txt', sep='\\t')\n",
    "test_values=data_test.values\n",
    "\n",
    "classes=[]\n",
    "for i in range(len(data_label['label'].values)):\n",
    "    cur=data_label['label'].values[i]\n",
    "    if cur not in classes:\n",
    "        classes.append(cur)\n",
    "classes.sort()\n",
    "\n",
    "train_listwav=[]\n",
    "listwavtot=[]\n",
    "train_listlabel=[]\n",
    "listlabeltot=[]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "valid_listwav=[]\n",
    "valid_listlabel=[]\n",
    "\n",
    "test_listwav=[]\n",
    "test_listlabel=[]\n",
    "\n",
    "n_mels=64\n",
    "frame_window=62\n",
    "input_shape = (1,frame_window, n_mels)\n",
    "\n",
    "train_sortedbylabel={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons ici le dictionnaire des fichiers audio d'entraînement, la clé correspond au label et les données à l'ensemble des fichiers ayant ce label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(classes)):\n",
    "    cur=[]\n",
    "    for i in range(len(train_values)):\n",
    "        if train_values[i][1]==classes[k]:\n",
    "            cur.append(train_values[i][0])\n",
    "            train_sortedbylabel[k]=cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons ici la fonction de création des utilisateurs que nous simulons. Cela revient à subdiviser notre ensemble d'apprentissages en plusieurs sous-ensembles selon des règles de division et de tri.\\\n",
    "Si la division est \"even\", alors on distribue dans des proportions équitable les exemples entre les utilisateurs.\\\n",
    "Si la division est \"random\", alors on distribue dans des proportions aléatoires les exemples entre les utilisateurs.\\\n",
    "Si le sorting est \"orderly\", alors les exemples sont donnés aux utilisateurs dans l'ordre de la trainlist.\\\n",
    "Si le sorting est \"random\", alors les exemples sont tirés aléatoirement dans la trainlist avant d'être donnés aux utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateUsers(trainlist,nb_users,division,sorting):\n",
    "    WavList=[]\n",
    "    DistributionList=[]\n",
    "    LabelList=[]\n",
    "    if division==\"even\" and sorting==\"orderly\":\n",
    "        for l in range(nb_users):\n",
    "            wav=[]\n",
    "            distrib=[]\n",
    "            label=[]\n",
    "            for k in range(len(trainlist)):\n",
    "                distrib.append(int(np.floor((len(trainlist[k]))/nb_users)))\n",
    "                for i in range(int(np.floor((len(trainlist[k]))/nb_users))):\n",
    "                    wav.append(trainlist[k][l*int(np.floor((len(trainlist[k]))/nb_users))+i])\n",
    "                    label.append(k)\n",
    "            WavList.append(wav)\n",
    "            DistributionList.append(distrib)\n",
    "            LabelList.append(label)\n",
    "    if division==\"random\" and sorting==\"orderly\":\n",
    "        s = np.random.uniform(0,1,nb_users)\n",
    "        for l in range(nb_users):\n",
    "            S=0\n",
    "            wav=[]\n",
    "            distrib=[]\n",
    "            label=[]\n",
    "            for k in range(len(trainlist)):\n",
    "                if k==0:\n",
    "                    S+=int(np.floor((s[l]/np.sum(s))*len(trainlist[k])))\n",
    "                distrib.append(int(np.floor((s[l]/np.sum(s))*len(trainlist[k]))))\n",
    "                for i in range(int(np.floor((s[l]/np.sum(s))*len(trainlist[k])))):\n",
    "                    wav.append(trainlist[k][int(np.floor((S/np.sum(s))))+i])\n",
    "                    label.append(k)\n",
    "            WavList.append(wav)\n",
    "            DistributionList.append(distrib)\n",
    "            LabelList.append(label)\n",
    "    if division==\"even\" and sorting==\"random\":\n",
    "        for l in range(nb_users):\n",
    "            wav=[]\n",
    "            distrib=[]\n",
    "            label=[]\n",
    "            for k in range(len(trainlist)):\n",
    "                tirage = np.random.choice(len(trainlist[k]), len(trainlist[k]),replace=False)\n",
    "                distrib.append(int(np.floor((len(trainlist[k]))/nb_users)))\n",
    "                for i in range(int(np.floor((len(trainlist[k]))/nb_users))):\n",
    "                    wav.append(trainlist[k][tirage[l*int(np.floor((len(trainlist[k]))/nb_users))+i]])\n",
    "                    label.append(k)\n",
    "            WavList.append(wav)\n",
    "            DistributionList.append(distrib)\n",
    "            LabelList.append(label)\n",
    "    if division==\"random\" and sorting==\"random\":\n",
    "        s = np.random.uniform(0,1,nb_users)\n",
    "        for l in range(nb_users):\n",
    "            S=0\n",
    "            wav=[]\n",
    "            distrib=[]\n",
    "            label=[]\n",
    "            for k in range(len(trainlist)):\n",
    "                tirage = np.random.choice(len(trainlist[k]), len(trainlist[k]),replace=False)\n",
    "                if k==0:\n",
    "                    S+=int(np.floor((s[l]/np.sum(s))*len(trainlist[k])))\n",
    "                distrib.append(int(np.floor((s[l]/np.sum(s))*len(trainlist[k]))))\n",
    "                for i in range(int(np.floor((s[l]/np.sum(s))*len(trainlist[k])))):\n",
    "                    wav.append(trainlist[k][tirage[int(np.floor((S/np.sum(s))))+i]])\n",
    "                    label.append(k)\n",
    "            WavList.append(wav)\n",
    "            DistributionList.append(distrib)\n",
    "            LabelList.append(label)\n",
    "    return WavList,DistributionList,LabelList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous simulons 5 utilisateurs, puis nous visualisons la distribution des données pour un des utilisateur en fonction des labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Users=CreateUsers(train_sortedbylabel,5,\"even\",\"orderly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e2b3ea09e8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Users[1][0])),Users[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous effectuons à présent le data pre-processing, nous convertissons nos fichiers audio en fichiers .npy pour ne conserver que le spectrogramme de mel du fichier, que nous convertissons en données chiffrées en dB pour une utilisation future dans notre réseau de neurone, c'est l'unique composante qui nous permettra de différencier les fichiers sons et faire l'apprentissage.\\\n",
    "Nous normalisons par la suite nos données pour améliorer l'apprentissage.\\\n",
    "Nous effectuons également le One-Hot Encoding sur les données de validation et de test pour être cohérent avec les modèles de machine learning que nous utilisons à la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for filename in train_listwav:\\n    wavename = os.path.join(basename,filename)\\n    # read the sound file\\n    data, sr = get_sound_data(wavename)\\n    # feature computation\\n    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\\n    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\\n    np.save('C:/Users/jaber/Downloads/PFE/Features/'+filename, logspec_full.T)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train_values)):\n",
    "    train_listwav.append(train_values[i][0])\n",
    "    listwavtot.append(train_values[i][0])\n",
    "    train_listlabel.append(train_values[i][1])\n",
    "    listlabeltot.append(train_values[i][1])\n",
    "# integer encode\n",
    "train_label_integer_encoded = label_encoder.fit_transform(train_listlabel)\n",
    "\"\"\"for filename in train_listwav:\n",
    "    wavename = os.path.join(basename,filename)\n",
    "    # read the sound file\n",
    "    data, sr = get_sound_data(wavename)\n",
    "    # feature computation\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\n",
    "    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/Features/'+filename, logspec_full.T)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for filename in valid_listwav:\\n    wavename = os.path.join(basename,filename)\\n    # read the sound file\\n    data, sr = get_sound_data(wavename)\\n    # feature computation\\n    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\\n    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\\n    np.save('C:/Users/jaber/Downloads/PFE/ValidFeatures/'+filename, logspec_full.T)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(valid_values)):\n",
    "    valid_listwav.append(valid_values[i][0])\n",
    "    listwavtot.append(valid_values[i][0])\n",
    "    valid_listlabel.append(valid_values[i][1])\n",
    "    listlabeltot.append(valid_values[i][1])\n",
    "# integer encode\n",
    "valid_label_integer_encoded = label_encoder.transform(valid_listlabel)\n",
    "\"\"\"for filename in valid_listwav:\n",
    "    wavename = os.path.join(basename,filename)\n",
    "    # read the sound file\n",
    "    data, sr = get_sound_data(wavename)\n",
    "    # feature computation\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\n",
    "    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/ValidFeatures/'+filename, logspec_full.T)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for filename in test_listwav:\\n    wavename = os.path.join(basename,filename)\\n    # read the sound file\\n    data, sr = get_sound_data(wavename)\\n    # feature computation\\n    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\\n    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\\n    np.save('C:/Users/jaber/Downloads/PFE/TestFeatures/'+filename, logspec_full.T)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test_values)):\n",
    "    test_listwav.append(test_values[i][0])\n",
    "    listwavtot.append(test_values[i][0])\n",
    "    test_listlabel.append(test_values[i][1])\n",
    "    listlabeltot.append(test_values[i][1])\n",
    "# integer encode\n",
    "test_label_integer_encoded = label_encoder.transform(test_listlabel)\n",
    "\"\"\"for filename in test_listwav:\n",
    "    wavename = os.path.join(basename,filename)\n",
    "    # read the sound file\n",
    "    data, sr = get_sound_data(wavename)\n",
    "    # feature computation\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(data,sr=sr,n_mels=64,hop_length=1024,n_fft=2048,fmin=50)\n",
    "    logspec_full = librosa.amplitude_to_db(mel_spectrogram)\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/TestFeatures/'+filename, logspec_full.T)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scaler = StandardScaler()\\nfeature_batch = []\\n#loop over all feature files in TRAINING SET\\nfor feature_filename in train_listwav:\\n    # load features\\n    features = np.load(open('C:/Users/jaber/Downloads/PFE/Features/'+feature_filename+'.npy', 'rb'))\\n    # append the features to the liste\\n    feature_batch.append(features)\\n    # flush the list every 5000 feature file\\n    if len(feature_batch) % 5000 == 0:\\n        # transform the list of feature arrays in a T x n_mels array\\n        feature_batch = np.concatenate(feature_batch)\\n        # compute\\n        scaler.partial_fit(feature_batch)\\n        feature_batch = []\\nif len(feature_batch) != 0:\\n    feature_batch = np.concatenate(feature_batch)\\n    scaler.partial_fit(feature_batch)\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"scaler = StandardScaler()\n",
    "feature_batch = []\n",
    "#loop over all feature files in TRAINING SET\n",
    "for feature_filename in train_listwav:\n",
    "    # load features\n",
    "    features = np.load(open('C:/Users/jaber/Downloads/PFE/Features/'+feature_filename+'.npy', 'rb'))\n",
    "    # append the features to the liste\n",
    "    feature_batch.append(features)\n",
    "    # flush the list every 5000 feature file\n",
    "    if len(feature_batch) % 5000 == 0:\n",
    "        # transform the list of feature arrays in a T x n_mels array\n",
    "        feature_batch = np.concatenate(feature_batch)\n",
    "        # compute\n",
    "        scaler.partial_fit(feature_batch)\n",
    "        feature_batch = []\n",
    "if len(feature_batch) != 0:\n",
    "    feature_batch = np.concatenate(feature_batch)\n",
    "    scaler.partial_fit(feature_batch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for feature_filename in train_listwav:\\n   # load features\\n   features = np.load(open('C:/Users/jaber/Downloads/PFE/Features/'+feature_filename+'.npy', 'rb'))\\n   # normalize features\\n   normalized_features = scaler.transform(features)\\n   # store normalized features\\n   np.save('C:/Users/jaber/Downloads/PFE/NormalizedFeatures/'+feature_filename+'normalized.npy', normalized_features)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #loop over all feature files\n",
    "\"\"\"for feature_filename in train_listwav:\n",
    "    # load features\n",
    "    features = np.load(open('C:/Users/jaber/Downloads/PFE/Features/'+feature_filename+'.npy', 'rb'))\n",
    "    # normalize features\n",
    "    normalized_features = scaler.transform(features)\n",
    "    # store normalized features\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/NormalizedFeatures/'+feature_filename+'normalized.npy', normalized_features)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for feature_filename in valid_listwav:\\n   # load features\\n   features = np.load(open('C:/Users/jaber/Downloads/PFE/ValidFeatures/'+feature_filename+'.npy', 'rb'))\\n   # normalize features\\n   normalized_features = scaler.transform(features)\\n   # store normalized features\\n   np.save('C:/Users/jaber/Downloads/PFE/NormalizedValidFeatures/'+feature_filename+'normalized.npy', normalized_features)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #loop over all feature files\n",
    "\"\"\"for feature_filename in valid_listwav:\n",
    "    # load features\n",
    "    features = np.load(open('C:/Users/jaber/Downloads/PFE/ValidFeatures/'+feature_filename+'.npy', 'rb'))\n",
    "    # normalize features\n",
    "    normalized_features = scaler.transform(features)\n",
    "    # store normalized features\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/NormalizedValidFeatures/'+feature_filename+'normalized.npy', normalized_features)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for feature_filename in test_listwav:\\n   # load features\\n   features = np.load(open('C:/Users/jaber/Downloads/PFE/TestFeatures/'+feature_filename+'.npy', 'rb'))\\n   # normalize features\\n   normalized_features = scaler.transform(features)\\n   # store normalized features\\n   np.save('C:/Users/jaber/Downloads/PFE/NormalizedTestFeatures/'+feature_filename+'normalized.npy', normalized_features)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #loop over all feature files\n",
    "\"\"\"for feature_filename in test_listwav:\n",
    "    # load features\n",
    "    features = np.load(open('C:/Users/jaber/Downloads/PFE/TestFeatures/'+feature_filename+'.npy', 'rb'))\n",
    "    # normalize features\n",
    "    normalized_features = scaler.transform(features)\n",
    "    # store normalized features\n",
    "    np.save('C:/Users/jaber/Downloads/PFE/NormalizedTestFeatures/'+feature_filename+'normalized.npy', normalized_features)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons maintenant les générateurs de données pour la validation et le test des performances de notre réseau de neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = DataGenerator(valid_listwav,\n",
    "                                valid_label_integer_encoded,\n",
    "                                'C:/Users/jaber/Downloads/PFE/NormalizedValidFeatures',\n",
    "                                batch_size=32,\n",
    "                                frame_window_length=frame_window,\n",
    "                                shuffle=False,\n",
    "                                undersampling='no',\n",
    "                                debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(test_listwav,\n",
    "                               test_label_integer_encoded,\n",
    "                               'C:/Users/jaber/Downloads/PFE/NormalizedTestFeatures',\n",
    "                               batch_size=32,\n",
    "                               frame_window_length=frame_window,\n",
    "                               shuffle=False,\n",
    "                               undersampling='no',\n",
    "                               debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons maintenant les paramètres pour mettre en place notre apprentissage et garder en  mémoire le meilleur réseau de neurone entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'C:/Users/jaber/Downloads/PFE/Models/Merging'\n",
    "model_name = 'model'\n",
    "model_path = os.path.join(model_directory,model_name + \".{epoch:02d}-{val_accuracy:.4f}.hdf5\")\n",
    "log_dir = 'C:/Users/jaber/Downloads/PFE/Logs'\n",
    "logs = TensorBoard(log_dir=log_dir,histogram_freq=0)\n",
    "model_directory = 'C:/Users/jaber/Downloads/PFE/Models/Merging'\n",
    "model_name = 'model'\n",
    "model_path = os.path.join(model_directory,model_name + \".{epoch:02d}-{val_accuracy:.4f}.hdf5\")\n",
    "log_dir = 'C:/Users/jaber/Downloads/PFE/Logs'\n",
    "logs = TensorBoard(log_dir=log_dir,histogram_freq=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous initialisons désormais cinq réseaux de neurones auxquels nous donnons les mêmes poids pour démarrer notre apprentissage fédéré dans des conditions similaire aux conditions théoriques.\\\n",
    "Nous compilons les modèles pour ne pas devoir l'effectuer à chaque étape de notre apprentissage.\\\n",
    "Nous initialisons nos générateurs de données d'entraînement qui ne prennent qu'une partie de l'ensemble de nos données d'entraînement pour simuler la condition réelle où nos utilisateurs sont dans des conditions différentes et que leurs données sont privées et non partagées avec la base de données globable, ce qui est le but de notre travail, garantir la confidentialité des données de nos utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models = 5\n",
    "fmodels = []\n",
    "save_models = []\n",
    "train_generators = []\n",
    "for i in range(nb_models):\n",
    "    fmodel = vggish_model(input_shape,\n",
    "                 len(classes),\n",
    "                 other_class=True,\n",
    "                 filters=[64, 128, 256, 512],\n",
    "                 n_layers=None,\n",
    "                 kernel_size=(3, 3),\n",
    "                 pool_size=(2, 2),\n",
    "                 data_format='channels_first',\n",
    "                 drop_out=0.5,\n",
    "                 output_activation='softmax')\n",
    "\n",
    "    fmodel.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "\n",
    "    if i != 0:\n",
    "        fmodel.set_weights(fmodels[0].get_weights())\n",
    "\n",
    "    fmodels.append(fmodel)\n",
    "    \n",
    "    model_name = 'model'+str(i+1)\n",
    "    model_path = os.path.join(model_directory,model_name + \".{epoch:02d}-{val_accuracy:.4f}.hdf5\")\n",
    "    save_model = ModelCheckpoint(filepath=model_path,\n",
    "                         monitor='val_accuracy',\n",
    "                         verbose=1,\n",
    "                         save_best_only=False,\n",
    "                         save_weights_only=False,\n",
    "                         mode='auto',\n",
    "                         period=1)\n",
    "    save_models.append(save_model)\n",
    "    \n",
    "    train_generator = DataGenerator(Users[0][i],\n",
    "                                Users[2][i],\n",
    "                                'C:/Users/jaber/Downloads/PFE/NormalizedFeatures',\n",
    "                                batch_size=32,\n",
    "                                frame_window_length=frame_window,\n",
    "                                shuffle=True,\n",
    "                                undersampling='no',\n",
    "                                debug=False)\n",
    "    train_generators.append(train_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous lançons notre apprentissage.\\\n",
    "Le nombre d'époque est variable, mais plus il est grand plus le réseau aura tendance à mieux classer les données et avoir une meilleure précision jusqu'à atteindre ses performance optimale.\\\n",
    "Si nous entraînons notre réseau de nouveau après qu'il ait atteint ce maximum nous risquons d'avoir du sur-apprentissage et une moins bonne généralisation pour notre validation et notre test.\\\n",
    "Dans nos conditions d'expérience la précision est une métrique intéressante car nos données sont équilibrées et nous n'avons pas des conditions de détection variables, c'est-à-dire que détecter ou non une classe en particulier n'a pas une conséquence plus grave que dans la moyenne, toutes conditions sont identiques.\\\n",
    "Dans notre apprentissage fédéré nous avons choisi de ne faire qu'une époque pour chaque utilisateur et de faire une fusion de nos modèles par la suite, c'est cohérent avec le fait que nous ne souhaitons pas utiliser de manière trop importante les capacités de calcul des utilisateurs, une époque ne dure pas très longtemps et cela permettrait avec une base de donnée dynamique de profiter au plus tôt des ajouts de données nouvelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "208/208 [==============================] - 20s 95ms/step - loss: 6.6448 - accuracy: 0.0448 - val_loss: 3.7822 - val_accuracy: 0.0161\n",
      "\n",
      "Epoch 00001: saving model to C:/Users/jaber/Downloads/PFE/Models/Merging\\model1.01-0.0161.hdf5\n",
      "Epoch 1/1\n",
      "207/207 [==============================] - 17s 82ms/step - loss: 6.6550 - accuracy: 0.0405 - val_loss: 3.7993 - val_accuracy: 0.0161\n",
      "\n",
      "Epoch 00001: saving model to C:/Users/jaber/Downloads/PFE/Models/Merging\\model2.01-0.0161.hdf5\n",
      "Epoch 1/1\n",
      "211/211 [==============================] - 17s 81ms/step - loss: 6.7669 - accuracy: 0.0458 - val_loss: 3.7481 - val_accuracy: 0.0310\n",
      "\n",
      "Epoch 00001: saving model to C:/Users/jaber/Downloads/PFE/Models/Merging\\model3.01-0.0310.hdf5\n",
      "Epoch 1/1\n",
      "211/211 [==============================] - 17s 81ms/step - loss: 6.7284 - accuracy: 0.0424 - val_loss: 3.4668 - val_accuracy: 0.0500\n",
      "\n",
      "Epoch 00001: saving model to C:/Users/jaber/Downloads/PFE/Models/Merging\\model4.01-0.0500.hdf5\n",
      "Epoch 1/1\n",
      "208/208 [==============================] - 17s 82ms/step - loss: 6.4701 - accuracy: 0.0451 - val_loss: 3.7977 - val_accuracy: 0.0207\n",
      "\n",
      "Epoch 00001: saving model to C:/Users/jaber/Downloads/PFE/Models/Merging\\model5.01-0.0207.hdf5\n"
     ]
    }
   ],
   "source": [
    "for k in range(1):\n",
    "    for l in range(nb_models):\n",
    "        fmodels[l].fit_generator(generator=train_generators[l],\n",
    "                    epochs=1,\n",
    "                    callbacks=[save_models[l],logs],\n",
    "                    validation_data=valid_generator)\n",
    "    weights = [model.get_weights() for model in fmodels]\n",
    "    new_weights = list()\n",
    "    \n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        new_weights.append(\n",
    "            [np.array(weights_).mean(axis=0)\\\n",
    "                for weights_ in zip(*weights_list_tuple)])\n",
    "    for j in range(nb_models):\n",
    "        fmodels[j].set_weights(new_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
